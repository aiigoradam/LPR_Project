{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, math\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tesserocr import PyTessBaseAPI, OEM, PSM\n",
    "from PIL import Image\n",
    "\n",
    "# CONFIG \n",
    "TRAIN_DIR = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\data\\A\\val\"\n",
    "METADATA_PATH = os.path.join(TRAIN_DIR, \"metadata.json\")\n",
    "N_WORKERS = 8\n",
    "\n",
    "# LOAD METADATA \n",
    "with open(METADATA_PATH, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "\n",
    "# WORKER FUNCTION \n",
    "def process_chunk(chunk):\n",
    "    \"\"\"\n",
    "    OCR all plates in <chunk> (list of metadata dicts).\n",
    "    Returns: (digit_ok, digit_total, plate_ok, plate_total, lines)\n",
    "    \"\"\"\n",
    "    with PyTessBaseAPI(oem=OEM.LSTM_ONLY, psm=PSM.SINGLE_WORD) as api:\n",
    "        api.SetVariable(\"tessedit_char_whitelist\", \"0123456789\")\n",
    "        api.SetVariable(\"load_system_dawg\", \"0\")\n",
    "        api.SetVariable(\"load_freq_dawg\", \"0\")\n",
    "\n",
    "        dig_ok = dig_tot = pl_ok = pl_tot = 0\n",
    "        out_lines = []\n",
    "\n",
    "        for rec in chunk:\n",
    "            idx = rec[\"index\"]\n",
    "            truth = rec[\"plate_number\"]\n",
    "            img = cv2.imread(os.path.join(TRAIN_DIR, f\"original_{idx}.png\"))\n",
    "            if img is None:\n",
    "                out_lines.append(f\"Plate {idx:4d} | [MISSING IMAGE]\")\n",
    "                continue\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, bin_ = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            ocr_str = \"\"\n",
    "            for i, (x, y, w, h) in enumerate(rec[\"digit_bboxes\"]):\n",
    "\n",
    "                patch = bin_[y : y + h, x : x + w]\n",
    "                # convert NumPy array to PIL for tesserocr\n",
    "                patch_pil = Image.fromarray(patch)\n",
    "                api.SetImage(patch_pil)\n",
    "\n",
    "                txt = api.GetUTF8Text().strip()\n",
    "                digit = txt[0] if txt and txt[0].isdigit() else \"\"\n",
    "                ocr_str += digit\n",
    "\n",
    "                dig_tot += 1\n",
    "                if digit == truth[i]:\n",
    "                    dig_ok += 1\n",
    "\n",
    "            if ocr_str == truth:\n",
    "                pl_ok += 1\n",
    "            pl_tot += 1\n",
    "\n",
    "            status = \"OK\" if ocr_str == truth else \"ERR\"\n",
    "            out_lines.append(f\"Plate {idx:4d} | GT={truth} | OCR={ocr_str:<6} | {status}\")\n",
    "\n",
    "        return dig_ok, dig_tot, pl_ok, pl_tot, out_lines\n",
    "\n",
    "\n",
    "# ── SPLIT WORK & RUN THREADS ──────────────────────────────────────────\n",
    "chunk_size = math.ceil(len(records) / N_WORKERS)\n",
    "chunks = [records[i : i + chunk_size] for i in range(0, len(records), chunk_size)]\n",
    "\n",
    "digit_ok = digit_tot = plate_ok = plate_tot = 0\n",
    "all_lines = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as exe:\n",
    "    futures = [exe.submit(process_chunk, c) for c in chunks]\n",
    "    for fut in as_completed(futures):\n",
    "        d_ok, d_tot, p_ok, p_tot, lines = fut.result()\n",
    "        digit_ok += d_ok\n",
    "        digit_tot += d_tot\n",
    "        plate_ok += p_ok\n",
    "        plate_tot += p_tot\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "# ── PRINT DETAIL (comment out if too verbose) ─────────────────────────\n",
    "for ln in sorted(all_lines):\n",
    "    print(ln)\n",
    "\n",
    "# ── SUMMARY ───────────────────────────────────────────────────────────\n",
    "print(\"\\nRESULTS\")\n",
    "print(f\"  Digit-level accuracy: {digit_ok / digit_tot * 100:.2f}% \" f\"({digit_ok}/{digit_tot})\")\n",
    "print(f\"  Plate-level accuracy: {plate_ok / plate_tot * 100:.2f}% \" f\"({plate_ok}/{plate_tot})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, math\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tesserocr import PyTessBaseAPI, OEM, PSM\n",
    "from PIL import Image\n",
    "\n",
    "# CONFIG \n",
    "DIR = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\results\\A\\restormer\"\n",
    "METADATA_DIR = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\data\\full_grid\"\n",
    "METADATA_PATH = os.path.join(METADATA_DIR, \"metadata.json\")\n",
    "N_WORKERS = 8\n",
    "\n",
    "# LOAD METADATA \n",
    "with open(METADATA_PATH, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "\n",
    "# WORKER FUNCTION \n",
    "def process_chunk(chunk):\n",
    "    \"\"\"\n",
    "    OCR all plates in <chunk> (list of metadata dicts).\n",
    "    Returns: (digit_ok, digit_total, plate_ok, plate_total, lines)\n",
    "    \"\"\"\n",
    "    with PyTessBaseAPI(oem=OEM.LSTM_ONLY, psm=PSM.SINGLE_WORD) as api:\n",
    "        api.SetVariable(\"tessedit_char_whitelist\", \"0123456789\")\n",
    "        api.SetVariable(\"load_system_dawg\", \"0\")\n",
    "        api.SetVariable(\"load_freq_dawg\", \"0\")\n",
    "\n",
    "\n",
    "        dig_ok = dig_tot = pl_ok = pl_tot = 0\n",
    "        out_lines = []\n",
    "\n",
    "        for rec in chunk:\n",
    "            idx = rec[\"index\"]\n",
    "            truth = rec[\"plate_number\"]\n",
    "            img = cv2.imread(os.path.join(DIR, f\"reconstructed_{idx}.png\"))\n",
    "            if img is None:\n",
    "                out_lines.append(f\"Plate {idx:4d} | [MISSING IMAGE]\")\n",
    "                continue\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, bin_ = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            ocr_str = \"\"\n",
    "            for i, (x, y, w, h) in enumerate(rec[\"digit_bboxes\"]):\n",
    "\n",
    "                patch = bin_[y : y + h, x : x + w]\n",
    "                # convert NumPy array to PIL for tesserocr\n",
    "                patch_pil = Image.fromarray(patch)\n",
    "                api.SetImage(patch_pil)\n",
    "\n",
    "                txt = api.GetUTF8Text().strip()\n",
    "                digit = txt[0] if txt and txt[0].isdigit() else \"\"\n",
    "                ocr_str += digit\n",
    "\n",
    "                dig_tot += 1\n",
    "                if digit == truth[i]:\n",
    "                    dig_ok += 1\n",
    "\n",
    "            if ocr_str == truth:\n",
    "                pl_ok += 1\n",
    "            pl_tot += 1\n",
    "\n",
    "            status = \"OK\" if ocr_str == truth else \"ERR\"\n",
    "            out_lines.append(f\"Plate {idx:4d} | GT={truth} | OCR={ocr_str:<6} | {status}\")\n",
    "\n",
    "        return dig_ok, dig_tot, pl_ok, pl_tot, out_lines\n",
    "\n",
    "\n",
    "# ── SPLIT WORK & RUN THREADS ──────────────────────────────────────────\n",
    "chunk_size = math.ceil(len(records) / N_WORKERS)\n",
    "chunks = [records[i : i + chunk_size] for i in range(0, len(records), chunk_size)]\n",
    "\n",
    "digit_ok = digit_tot = plate_ok = plate_tot = 0\n",
    "all_lines = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as exe:\n",
    "    futures = [exe.submit(process_chunk, c) for c in chunks]\n",
    "    for fut in as_completed(futures):\n",
    "        d_ok, d_tot, p_ok, p_tot, lines = fut.result()\n",
    "        digit_ok += d_ok\n",
    "        digit_tot += d_tot\n",
    "        plate_ok += p_ok\n",
    "        plate_tot += p_tot\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "# ── PRINT DETAIL (comment out if too verbose) ─────────────────────────\n",
    "for ln in sorted(all_lines):\n",
    "    # only print plates where OCR != GT\n",
    "    if \"| ERR\" in ln or \"[MISSING IMAGE]\" in ln:\n",
    "        print(ln)\n",
    "        \n",
    "# ── SUMMARY ───────────────────────────────────────────────────────────\n",
    "print(\"\\nRESULTS\")\n",
    "print(f\"  Digit-level accuracy: {digit_ok / digit_tot * 100:.2f}% \" f\"({digit_ok}/{digit_tot})\")\n",
    "print(f\"  Plate-level accuracy: {plate_ok / plate_tot * 100:.2f}% \" f\"({plate_ok}/{plate_tot})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# ── CONFIG ──────────────────────────────────────────────────────────────\n",
    "DATA_DIR = \"results/A/restormer\"  \n",
    "\n",
    "# error list: (index, OCR_str)\n",
    "errors = [\n",
    "    (39522, \"602395\"),\n",
    "    (39523, \"137218\"),\n",
    "    (39524, \"865378\"),\n",
    "    (39525, \"653310\"),\n",
    "    (39526, \"389910\"),\n",
    "    (39527, \"464894\"),\n",
    "    (39528, \"289290\"),\n",
    "    (39529, \"029805\"),\n",
    "    (39530, \"436875\"),\n",
    "    (39531, \"738414\"),\n",
    "    (39532, \"489838\"),\n",
    "    (39533, \"889556\"),\n",
    "    (39534, \"082369\"),\n",
    "    (39535, \"423725\"),\n",
    "    (39536, \"888024\"),\n",
    "    (39537, \"845095\"),\n",
    "    (39538, \"826932\"),\n",
    "    (39539, \"911231\"),\n",
    "    (39540, \"230770\"),\n",
    "    (39541, \"735023\"),\n",
    "    (39542, \"325040\"),\n",
    "    (39543, \"323484\"),\n",
    "    (39544, \"338354\"),\n",
    "    (39545, \"755102\"),\n",
    "    (39546, \"707206\"),\n",
    "    (39547, \"449489\"),\n",
    "    (39548, \"479843\"),\n",
    "    (39549, \"133239\"),\n",
    "    (39550, \"301370\"),\n",
    "    (39551, \"588666\"),\n",
    "    (39552, \"733089\"),\n",
    "    (39553, \"745937\"),\n",
    "    (39554, \"763805\"),\n",
    "    (39555, \"881739\"),\n",
    "    (39556, \"982350\"),\n",
    "    (39557, \"482399\"),\n",
    "    (39558, \"147356\"),\n",
    "    (39559, \"103312\"),\n",
    "]\n",
    "\n",
    "# ── PLOTTING ─────────────────────────────────────────────────────────────\n",
    "n = len(errors)\n",
    "cols = 5\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "plt.figure(figsize=(cols * 4, rows * 1.3))\n",
    "for i, (idx, ocr_str) in enumerate(errors, start=1):\n",
    "    img_path = os.path.join(DATA_DIR, f\"reconstructed_{idx}.png\")\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    ax  = plt.subplot(rows, cols, i)\n",
    "    ax.imshow(img)\n",
    "    # Title now includes the plate index before the OCR result\n",
    "    ax.set_title(f\"idx:{idx} | OCR:{ocr_str}\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, math\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tesserocr import PyTessBaseAPI, OEM, PSM\n",
    "from PIL import Image\n",
    "\n",
    "# ── CONFIG ─────────────────────────────────────────────────────────────\n",
    "DIR             = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\results\\A\\restormer\"\n",
    "METADATA_DIR    = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\data\\full_grid\"\n",
    "METADATA_PATH   = os.path.join(METADATA_DIR, \"metadata.json\")\n",
    "LIST_PATH       = \"list.txt\"         # project root file listing the plates\n",
    "N_WORKERS       = 8\n",
    "# ── END CONFIG ─────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) Load the “list.txt” of plates to check\n",
    "plates_to_check = {}\n",
    "with open(LIST_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\"|\")\n",
    "        idx = int(parts[0].split()[1])\n",
    "        gt  = parts[1].split(\"=\")[1]\n",
    "        plates_to_check[idx] = gt\n",
    "\n",
    "# 2) Load full metadata and filter\n",
    "with open(METADATA_PATH, \"r\") as f:\n",
    "    all_records = json.load(f)\n",
    "\n",
    "records = []\n",
    "for rec in all_records:\n",
    "    idx = rec[\"index\"]\n",
    "    if idx in plates_to_check:\n",
    "        rec[\"plate_number\"] = plates_to_check[idx]\n",
    "        records.append(rec)\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(\"No matching plates found in metadata.json\")\n",
    "\n",
    "# 3) Worker function\n",
    "def process_chunk(chunk):\n",
    "    with PyTessBaseAPI(oem=OEM.LSTM_ONLY, psm=PSM.SINGLE_WORD) as api:\n",
    "        api.SetVariable(\"tessedit_char_whitelist\", \"0123456789\")\n",
    "        api.SetVariable(\"load_system_dawg\", \"0\")\n",
    "        api.SetVariable(\"load_freq_dawg\", \"0\")\n",
    "        api.SetVariable(\"classify_bln_numeric_mode\", \"1\")\n",
    "        api.SetVariable(\"tessedit_minimal_rej_pass1\", \"0\")\n",
    "        api.SetVariable(\"tessedit_reject_bad_permuter\", \"0\")\n",
    "\n",
    "        dig_ok = dig_tot = pl_ok = pl_tot = nonblank_ok = nonblank_tot = 0\n",
    "        out_lines = []\n",
    "\n",
    "        for rec in chunk:\n",
    "            idx   = rec[\"index\"]\n",
    "            truth = rec[\"plate_number\"]\n",
    "            img = cv2.imread(os.path.join(DIR, f\"reconstructed_{idx}.png\"))\n",
    "            if img is None:\n",
    "                out_lines.append(f\"Plate {idx:4d} | [MISSING IMAGE]\")\n",
    "                continue\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, bin_ = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            ocr_str = \"\"\n",
    "            for i, (x, y, w, h) in enumerate(rec[\"digit_bboxes\"]):\n",
    "                patch = bin_[y : y + h, x : x + w]\n",
    "                patch_pil = Image.fromarray(patch)\n",
    "                api.SetImage(patch_pil)\n",
    "\n",
    "                txt = api.GetUTF8Text().strip()\n",
    "                digit = txt[0] if txt and txt[0].isdigit() else \"\"\n",
    "                ocr_str += digit\n",
    "\n",
    "                dig_tot += 1\n",
    "                if digit == truth[i]:\n",
    "                    dig_ok += 1\n",
    "\n",
    "            # plate-level correctness\n",
    "            if ocr_str == truth:\n",
    "                pl_ok += 1\n",
    "            pl_tot += 1\n",
    "\n",
    "            # six-digit (non-blank) check\n",
    "            if len(ocr_str) == len(truth) and all(c != \"\" for c in ocr_str):\n",
    "                nonblank_ok += 1\n",
    "            nonblank_tot += 1\n",
    "\n",
    "            status = \"OK\" if ocr_str == truth else \"ERR\"\n",
    "            out_lines.append(f\"Plate {idx:4d} | GT={truth} | OCR={ocr_str:<6} | {status}\")\n",
    "\n",
    "        return (dig_ok, dig_tot,\n",
    "                pl_ok, pl_tot,\n",
    "                nonblank_ok, nonblank_tot,\n",
    "                out_lines)\n",
    "\n",
    "# 4) Split into chunks and run threads\n",
    "chunk_size = math.ceil(len(records) / N_WORKERS)\n",
    "chunks = [records[i : i + chunk_size] for i in range(0, len(records), chunk_size)]\n",
    "\n",
    "digit_ok = digit_tot = plate_ok = plate_tot = 0\n",
    "nonblank_ok = nonblank_tot = 0\n",
    "all_lines = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as exe:\n",
    "    futures = [exe.submit(process_chunk, c) for c in chunks]\n",
    "    for fut in as_completed(futures):\n",
    "        (d_ok, d_tot,\n",
    "         p_ok, p_tot,\n",
    "         nb_ok, nb_tot,\n",
    "         lines) = fut.result()\n",
    "\n",
    "        digit_ok     += d_ok\n",
    "        digit_tot    += d_tot\n",
    "        plate_ok     += p_ok\n",
    "        plate_tot    += p_tot\n",
    "        nonblank_ok  += nb_ok\n",
    "        nonblank_tot += nb_tot\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "# 5) Print only failures\n",
    "for ln in sorted(all_lines):\n",
    "    if \"| ERR\" in ln or \"[MISSING IMAGE]\" in ln:\n",
    "        print(ln)\n",
    "\n",
    "# 6) Summary\n",
    "print(\"\\nRESULTS\")\n",
    "print(f\"  Digit-level accuracy: {digit_ok / digit_tot * 100:.2f}% \"\n",
    "      f\"({digit_ok}/{digit_tot})\")\n",
    "print(f\"  Plate-level accuracy: {plate_ok / plate_tot * 100:.2f}% \"\n",
    "      f\"({plate_ok}/{plate_tot})\")\n",
    "print(f\"  Plates with all digits non-blank: {nonblank_ok / nonblank_tot * 100:.2f}% \"\n",
    "      f\"({nonblank_ok}/{nonblank_tot})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tesserocr import PyTessBaseAPI, OEM, PSM\n",
    "from PIL import Image\n",
    "\n",
    "# ── CONFIG ─────────────────────────────────────────────────────────────\n",
    "DIR             = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\results\\A\\restormer\"\n",
    "METADATA_DIR    = r\"C:\\Users\\stopc\\Desktop\\LPR_Project\\data\\full_grid\"\n",
    "METADATA_PATH   = os.path.join(METADATA_DIR, \"metadata.json\")\n",
    "N_WORKERS       = 8\n",
    "UPSCALE_FACTOR  = 2\n",
    "FALLBACK_DIGIT  = \"0\"\n",
    "# ── END CONFIG ─────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) Load full metadata (each rec must include \"index\", \"plate_number\", and \"digit_bboxes\")\n",
    "with open(METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = json.load(f)\n",
    "if not records:\n",
    "    raise RuntimeError(\"No records found in metadata.json\")\n",
    "\n",
    "# 2) Binarisation / upscaling recipes (always with digit whitelist)\n",
    "RECIPES = [\n",
    "    (\"fixed\",    False, PSM.SINGLE_WORD),\n",
    "    (\"otsu\",     False, PSM.SINGLE_WORD),\n",
    "    (\"adaptive\", False, PSM.SINGLE_CHAR),\n",
    "    (\"fixed\",    True,  PSM.SINGLE_CHAR),\n",
    "    (\"otsu\",     True,  PSM.SINGLE_WORD),\n",
    "]\n",
    "\n",
    "def preprocess(gray, mode, invert):\n",
    "    flag = cv2.THRESH_BINARY_INV if invert else cv2.THRESH_BINARY\n",
    "    if mode == \"fixed\":\n",
    "        _, bin_img = cv2.threshold(gray, 150, 255, flag)\n",
    "    elif mode == \"otsu\":\n",
    "        _, bin_img = cv2.threshold(gray, 0, 255, flag | cv2.THRESH_OTSU)\n",
    "    elif mode == \"adaptive\":\n",
    "        bin_img = cv2.adaptiveThreshold(gray, 255,\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        flag, 11, 2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "    return bin_img\n",
    "\n",
    "# 3) Patch-level OCR → (digit_char, used_fallback_flag)\n",
    "def ocr_single_digit(api, gray_patch):\n",
    "    for mode, inv, psm in RECIPES:\n",
    "        bin_p = preprocess(gray_patch, mode, inv)\n",
    "        h, w = bin_p.shape\n",
    "        up   = cv2.resize(bin_p, (w*UPSCALE_FACTOR, h*UPSCALE_FACTOR),\n",
    "                          cv2.INTER_CUBIC)\n",
    "\n",
    "        api.SetPageSegMode(psm)\n",
    "        api.SetVariable(\"tessedit_char_whitelist\", \"0123456789\")\n",
    "        api.SetVariable(\"classify_bln_numeric_mode\",   \"1\")\n",
    "\n",
    "        api.SetImage(Image.fromarray(up))\n",
    "        api.Recognize()\n",
    "        txt = api.GetUTF8Text() or \"\"\n",
    "        for ch in txt:\n",
    "            if ch.isdigit():\n",
    "                return ch, False\n",
    "\n",
    "    # none succeeded → fallback\n",
    "    return FALLBACK_DIGIT, True\n",
    "\n",
    "# 4) Full-plate OCR rescue → digit string (possibly shorter)\n",
    "def ocr_full_plate(api, gray_plate):\n",
    "    for mode, inv, psm in RECIPES:\n",
    "        bin_p = preprocess(gray_plate, mode, inv)\n",
    "        h, w = bin_p.shape\n",
    "        up   = cv2.resize(bin_p, (w*UPSCALE_FACTOR, h*UPSCALE_FACTOR),\n",
    "                          cv2.INTER_CUBIC)\n",
    "\n",
    "        api.SetPageSegMode(psm)\n",
    "        api.SetVariable(\"tessedit_char_whitelist\", \"0123456789\")\n",
    "        api.SetVariable(\"classify_bln_numeric_mode\",   \"1\")\n",
    "\n",
    "        api.SetImage(Image.fromarray(up))\n",
    "        api.Recognize()\n",
    "        digits = \"\".join(ch for ch in (api.GetUTF8Text() or \"\") if ch.isdigit())\n",
    "        if digits:\n",
    "            return digits\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "# 5) Worker: process a list of records\n",
    "def process_chunk(chunk):\n",
    "    with PyTessBaseAPI(oem=OEM.LSTM_ONLY, psm=PSM.SINGLE_WORD) as api:\n",
    "        dig_ok = dig_tot = pl_ok = pl_tot = 0\n",
    "        plates_no_fallback = 0\n",
    "        out_lines = []\n",
    "\n",
    "        for rec in chunk:\n",
    "            idx   = rec[\"index\"]\n",
    "            truth = rec[\"plate_number\"]\n",
    "            img   = cv2.imread(os.path.join(DIR, f\"reconstructed_{idx}.png\"))\n",
    "            if img is None:\n",
    "                out_lines.append(f\"Plate {idx:4d} | [MISSING IMAGE]\")\n",
    "                continue\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # ── patch-level OCR ────────────────────────────────────────\n",
    "            chars     = []\n",
    "            fb_mask   = []\n",
    "            for i, (x, y, w, h) in enumerate(rec[\"digit_bboxes\"]):\n",
    "                digit, fb = ocr_single_digit(api, gray[y:y+h, x:x+w])\n",
    "                chars.append(digit)\n",
    "                fb_mask.append(fb)\n",
    "                dig_tot += 1\n",
    "                if digit == truth[i]:\n",
    "                    dig_ok += 1\n",
    "\n",
    "            # ── full-plate rescue if needed ───────────────────────────\n",
    "            if any(fb_mask):\n",
    "                full = ocr_full_plate(api, gray)\n",
    "                if len(full) >= len(chars):\n",
    "                    for i, fb in enumerate(fb_mask):\n",
    "                        if fb:\n",
    "                            chars[i]   = full[i]\n",
    "                            fb_mask[i] = False\n",
    "\n",
    "            plate_ocr = \"\".join(chars)\n",
    "            if plate_ocr == truth:\n",
    "                pl_ok += 1\n",
    "            pl_tot += 1\n",
    "            if not any(fb_mask):\n",
    "                plates_no_fallback += 1\n",
    "\n",
    "            out_lines.append(\n",
    "                f\"Plate {idx:4d} | GT={truth} | OCR={plate_ocr:<6} | \"\n",
    "                f\"{'OK' if plate_ocr==truth else 'ERR'}\"\n",
    "            )\n",
    "\n",
    "        return dig_ok, dig_tot, pl_ok, pl_tot, plates_no_fallback, out_lines\n",
    "\n",
    "# ── SPLIT & RUN ────────────────────────────────────────────────────────\n",
    "chunk_size = math.ceil(len(records) / N_WORKERS)\n",
    "chunks     = [records[i : i + chunk_size] for i in range(0, len(records), chunk_size)]\n",
    "\n",
    "digit_ok = digit_tot = plate_ok = plate_tot = total_no_fallback = 0\n",
    "all_lines = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as exe:\n",
    "    futures = [exe.submit(process_chunk, c) for c in chunks]\n",
    "    for fut in as_completed(futures):\n",
    "        d_ok, d_tot, p_ok, p_tot, no_fb, lines = fut.result()\n",
    "        digit_ok        += d_ok\n",
    "        digit_tot       += d_tot\n",
    "        plate_ok        += p_ok\n",
    "        plate_tot       += p_tot\n",
    "        total_no_fallback += no_fb\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "# ── DETAIL (only errors) ───────────────────────────────────────────────\n",
    "for ln in sorted(all_lines):\n",
    "    if \"| ERR\" in ln or \"[MISSING IMAGE]\" in ln:\n",
    "        print(ln)\n",
    "\n",
    "# ── SUMMARY ────────────────────────────────────────────────────────────\n",
    "print(\"\\nRESULTS\")\n",
    "print(f\"  Digit-level accuracy: {digit_ok/ digit_tot*100:.2f}% \"\n",
    "      f\"({digit_ok}/{digit_tot})\")\n",
    "print(f\"  Plate-level accuracy: {plate_ok/ plate_tot*100:.2f}% \"\n",
    "      f\"({plate_ok}/{plate_tot})\")\n",
    "\n",
    "total_plates = len(records)\n",
    "fallback_plates = total_plates - total_no_fallback\n",
    "print(f\"  Plates with all digits from Tesseract (no fallbacks): \"\n",
    "      f\"{total_no_fallback}/{total_plates} \"\n",
    "      f\"({total_no_fallback/total_plates*100:.2f}%)\")\n",
    "print(f\"  Plates requiring at least one fallback '0': \"\n",
    "      f\"{fallback_plates}/{total_plates} \"\n",
    "      f\"({fallback_plates/total_plates*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.lp_processing import (\n",
    "    create_license_plate,\n",
    "    warp_image,\n",
    "    simulate_noise,\n",
    "    dewarp_image,\n",
    "    crop_to_original_size,\n",
    ")\n",
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "# --- Test parameters (now 256×64 plates) ---\n",
    "alpha, beta = 84, 0\n",
    "width, height = 512, 128\n",
    "text_size = 100\n",
    "focal_length = width  # matches production f=original_width\n",
    "\n",
    "# 1. Create a clean plate (PIL image in RGB) and get its corners\n",
    "plate_pil, src_points, plate_number, _ = create_license_plate(width, height, text_size)\n",
    "\n",
    "# 2. PIL → NumPy (RGB)\n",
    "plate_rgb = np.array(plate_pil)\n",
    "\n",
    "# 3. Warp (expects RGB, returns RGB)\n",
    "warped_rgb, dst_points = warp_image(plate_rgb, np.array(src_points), alpha, beta, focal_length)\n",
    "\n",
    "# 4. Noise (expects RGB, returns RGB)\n",
    "noisy_rgb = simulate_noise(warped_rgb)\n",
    "\n",
    "# 5. Dewarp (expects RGB, returns RGB)\n",
    "dewarped_rgb = dewarp_image(noisy_rgb, src_points, dst_points)\n",
    "\n",
    "orig_crop   = crop_to_original_size(plate_rgb,   width, height)\n",
    "dewarp_crop = crop_to_original_size(dewarped_rgb, width, height)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "\n",
    "axes[0].imshow(orig_crop)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title(f'Original Plate')\n",
    "\n",
    "axes[1].imshow(noisy_rgb)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Warped + Simulated Camera Noise')\n",
    "\n",
    "axes[2].imshow(dewarp_crop)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title(f'Distorted Plate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Heatmap of worst PSNR, SSIM, and OCR in parallel\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment(\"Unet\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Unet\")\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id, order_by=[\"attributes.start_time DESC\"], max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# --------------------\n",
    "# Functions\n",
    "# --------------------\n",
    "\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    config = r\"--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789\"\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return \"?\"\n",
    "\n",
    "\n",
    "def align_and_update_bboxes(original_np, generated_np, digit_bboxes):\n",
    "    search_margin = 16\n",
    "\n",
    "    def process_digit_bbox(bbox):\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y : y + h, x : x + w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(generated_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(generated_np.shape[0], y + h + search_margin)\n",
    "        search_region = generated_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        aligned_digit = generated_np[best_y : best_y + h, best_x : best_x + w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2, 0, 1)).unsqueeze(0)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "\n",
    "        return psnr_val, ssim_val, (best_x, best_y, w, h)\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_digit_bbox)(bbox) for bbox in digit_bboxes)\n",
    "    psnr_values = [r[0] for r in results]\n",
    "    ssim_values = [r[1] for r in results]\n",
    "    updated_bboxes = [r[2] for r in results]\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "\n",
    "def compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin):\n",
    "    def process_bbox(bbox):\n",
    "        x, y, w, h = bbox\n",
    "        x1 = max(0, x - margin)\n",
    "        y1 = max(0, y - margin)\n",
    "        x2 = min(image_bgr.shape[1], x + w + margin)\n",
    "        y2 = min(image_bgr.shape[0], y + h + margin)\n",
    "        digit_patch = image_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        return recognized_digit\n",
    "\n",
    "    recognized_digits = Parallel(n_jobs=-1)(delayed(process_bbox)(bbox) for bbox in updated_bboxes)\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Compute metrics for each (alpha, beta)\n",
    "# --------------------------------------\n",
    "metadata_path = os.path.join(data_dir, \"metadata.json\")\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    metadata_list = json.load(f)\n",
    "\n",
    "psnr_dict_worst = {}\n",
    "ssim_dict_worst = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "for metadata in tqdm(metadata_list, desc=\"Processing images\", unit=\"plate\"):\n",
    "    alpha = metadata[\"alpha\"]\n",
    "    beta = metadata[\"beta\"]\n",
    "    digit_bboxes = metadata[\"digit_bboxes\"]\n",
    "    plate_number_gt = metadata[\"plate_number\"]\n",
    "    index = metadata[\"index\"]\n",
    "\n",
    "    index = metadata[\"index\"]\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_img = model(distorted_img)\n",
    "        generated_img = torch.clamp(generated_img, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    generated_np = generated_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Parallelized CPU operations\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, generated_np, digit_bboxes)\n",
    "    image_bgr = (generated_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(\n",
    "        image_bgr, updated_bboxes, plate_number_gt, margin=2\n",
    "    )\n",
    "\n",
    "    # Take worst PSNR and SSIM\n",
    "    worst_psnr = np.min(psnr_per_number) if psnr_per_number else 0.0\n",
    "    worst_ssim = np.min(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_worst:\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "        ssim_dict_worst[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "    ssim_dict_worst[(alpha, beta)].append(worst_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_worst.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_worst.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_index = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_index = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val_list in data_dict.items():\n",
    "        val = np.min(val_list) if val_list else np.nan\n",
    "        mat[beta_to_index[b], alpha_to_index[a]] = val\n",
    "    return mat\n",
    "\n",
    "\n",
    "psnr_matrix = create_matrix_from_dict(psnr_dict_worst)\n",
    "ssim_matrix = create_matrix_from_dict(ssim_dict_worst)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_details_for(alpha, beta):\n",
    "    # find the one record in metadata_list\n",
    "    found = next((m for m in metadata_list if m[\"alpha\"] == alpha and m[\"beta\"] == beta), None)\n",
    "    if found is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    # unpack everything from `found`\n",
    "    index = found[\"index\"]\n",
    "    plate_number_gt = found[\"plate_number\"]\n",
    "    digit_bboxes = sorted(found[\"digit_bboxes\"], key=lambda b: b[0])\n",
    "\n",
    "    # file paths\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    # load & run the model\n",
    "    orig_t = to_tensor(Image.open(original_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    dist_t = to_tensor(Image.open(distorted_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        gen_t = model(dist_t).clamp(0.0, 1.0)\n",
    "\n",
    "    # to numpy\n",
    "    orig_np = orig_t.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    gen_np = gen_t.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # compute per-digit PSNR/SSIM + updated bboxes\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(orig_np, gen_np, digit_bboxes)\n",
    "\n",
    "    # load for display\n",
    "    distorted_image_cv = cv2.imread(distorted_path)\n",
    "    distorted_image_rgb = cv2.cvtColor(distorted_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Original image (with rectangles and text)\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, (x, y, w, h) in enumerate(digit_bboxes, start=1):\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        cv2.putText(original_image_cv, str(i), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Generated image (with rectangles and text)\n",
    "    generated_bgr = (gen_np * 255).astype(np.uint8)\n",
    "    generated_bgr = cv2.cvtColor(generated_bgr, cv2.COLOR_RGB2BGR)\n",
    "    generated_show = generated_bgr.copy()\n",
    "    for i, (x, y, w, h) in enumerate(updated_bboxes, start=1):\n",
    "        cv2.rectangle(generated_show, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        cv2.putText(generated_show, str(i), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "    generated_image_rgb = cv2.cvtColor(generated_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(\n",
    "        generated_bgr, updated_bboxes, plate_number_gt, margin=2\n",
    "    )\n",
    "\n",
    "    # Prepare table\n",
    "    table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "    for i, (p, s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    # Plot in three rows\n",
    "    fig2 = plt.figure(figsize=(11, 9))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(distorted_image_rgb)\n",
    "    plt.title(f\"Distorted (α={alpha}, β={beta})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.imshow(generated_image_rgb)\n",
    "    plt.title(\n",
    "        f\"Generated (GT={plate_number_gt}, Rec={recognized_text}, OCR Acc={ocr_accuracy*100:.1f}%, Bin={int(ocr_binary)})\"\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Table underneath\n",
    "    tbl = plt.table(cellText=transposed_table_data, cellLoc=\"center\", loc=\"center\", bbox=[0, -0.5, 1, 0.4])\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        psnr_value = psnr_matrix_clipped[row, col]\n",
    "        return (\n",
    "            f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: {psnr_value:.2f} dB\"\n",
    "            if not np.isnan(psnr_value)\n",
    "            else f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: N/A\"\n",
    "        )\n",
    "    return \"Alpha: N/A, Beta: N/A\"\n",
    "\n",
    "\n",
    "psnr_matrix_clipped = np.clip(psnr_matrix, None, 20)\n",
    "\n",
    "current_metric = \"PSNR\"\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "plt.subplots_adjust(bottom=0.15)  # space for buttons\n",
    "\n",
    "# Draw initial heatmap\n",
    "im = ax.imshow(psnr_matrix_clipped, origin=\"lower\", aspect=\"auto\", cmap=\"viridis\")\n",
    "ax.set_title(\"Worst PSNR per Image (Minimum Digit PSNR)\")\n",
    "cbar = plt.colorbar(im, ax=ax, label=\"PSNR (dB)\")\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "ax.format_coord = format_coord  # Set the coordinate display format\n",
    "\n",
    "# Define button positions\n",
    "button_width = 0.1  # Button width\n",
    "button_height = 0.05  # Button height\n",
    "button_spacing = 0.02  # Space between buttons\n",
    "\n",
    "# Compute x-coordinates for buttons\n",
    "x_start = 0.2  # Starting x-position\n",
    "y_position = 0.03\n",
    "x_psnr = x_start\n",
    "x_ssim = x_psnr + button_width + button_spacing\n",
    "x_ocr_acc = x_ssim + button_width + button_spacing\n",
    "x_ocr_bin = x_ocr_acc + button_width + button_spacing\n",
    "\n",
    "# Add buttons\n",
    "ax_psnr = plt.axes([x_psnr, y_position, button_width, button_height])\n",
    "ax_ssim = plt.axes([x_ssim, y_position, button_width, button_height])\n",
    "ax_ocr_acc = plt.axes([x_ocr_acc, y_position, button_width, button_height])\n",
    "ax_ocr_bin = plt.axes([x_ocr_bin, y_position, button_width, button_height])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, \"PSNR\")\n",
    "btn_ssim = Button(ax_ssim, \"SSIM\")\n",
    "btn_ocr_acc = Button(ax_ocr_acc, \"OCR Acc\")\n",
    "btn_ocr_bin = Button(ax_ocr_bin, \"OCR Bin\")\n",
    "\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "\n",
    "    if metric == \"PSNR\":\n",
    "        data = psnr_matrix_clipped\n",
    "        title = \"Worst PSNR per Image (Minimum Digit PSNR)\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == \"SSIM\":\n",
    "        data = ssim_matrix\n",
    "        title = \"Worst SSIM per Image (Minimum Digit SSIM)\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == \"OCR_Accuracy\":\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary Accuracy (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    # Update heatmap\n",
    "    im = ax.imshow(data, origin=\"lower\", aspect=\"auto\", cmap=\"viridis\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, num_alphas, 5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0, num_betas, 5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "    # Update colorbar\n",
    "    cbar.mappable = im\n",
    "    cbar.set_label(cbar_label)\n",
    "    cbar.update_normal(im)\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap(\"PSNR\")\n",
    "\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap(\"SSIM\")\n",
    "\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap(\"OCR_Accuracy\")\n",
    "\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap(\"OCR_Binary\")\n",
    "\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "\n",
    "# Connect the click event after setting up the entire figure\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:  # Ensure the click is within the heatmap axis\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "\n",
    "cid = fig.canvas.mpl_connect(\"button_press_event\", on_click)  # Connect after all setups\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
