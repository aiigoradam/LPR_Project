{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Digit Alignment Using Template Matching\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from PIL import Image\n",
    "\n",
    "# Target alpha and beta values\n",
    "target_alpha = 88\n",
    "target_beta = 2\n",
    "\n",
    "# Directory containing metadata files and images\n",
    "data_dir = \"data/full_grid\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set the MLflow experiment and load the model\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# Define PSNR calculation\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "# Transform to convert PIL image to tensor in [0,1]\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Scan metadata files\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "found_file = None\n",
    "\n",
    "# Find matching alpha and beta\n",
    "for meta_file in metadata_files:\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    if metadata.get('alpha') == target_alpha and metadata.get('beta') == target_beta:\n",
    "        found_file = {\n",
    "            \"metadata_file\": meta_file,\n",
    "            \"index\": metadata.get('index'),\n",
    "            \"digit_bboxes\": metadata.get('digit_bboxes'),\n",
    "            \"plate_number\": metadata.get('plate_number')\n",
    "        }\n",
    "        break\n",
    "\n",
    "print(f\"Found metadata file: {found_file['metadata_file']}\")\n",
    "print(f\"Alpha: {target_alpha}, Beta: {target_beta}\")\n",
    "print(f\"Plate Number: {found_file['plate_number']}\")\n",
    "\n",
    "# Sort bounding boxes\n",
    "original_bboxes = sorted(found_file['digit_bboxes'], key=lambda bbox: bbox[0])\n",
    "\n",
    "# Load images\n",
    "original_image_path = os.path.join(data_dir, f\"original_{found_file['index']}.png\")\n",
    "distorted_image_path = os.path.join(data_dir, f\"distorted_{found_file['index']}.png\")\n",
    "\n",
    "original_img = to_tensor(Image.open(original_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "distorted_img = to_tensor(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_tensor = model(distorted_img)\n",
    "    reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "# Convert to NumPy\n",
    "original_np = original_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "reconstructed_np = reconstructed_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Align and update bounding boxes for the reconstructed image\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        # Extract original digit\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Extract aligned digit\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Compute metrics\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "# Perform alignment\n",
    "psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, original_bboxes)\n",
    "\n",
    "# Visualization\n",
    "reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "reconstructed_show = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "original_image_cv = cv2.imread(original_image_path)\n",
    "\n",
    "# Draw original bounding boxes\n",
    "for i, bbox in enumerate(original_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    cv2.putText(original_image_cv, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "# Draw updated bounding boxes on reconstructed image\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(reconstructed_show, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    cv2.putText(reconstructed_show, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prepare table\n",
    "table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "for i, (psnr_val, ssim_val) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "    table_data.append([str(i), f\"{psnr_val:.2f}\", f\"{ssim_val:.3f}\"])\n",
    "transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(reconstructed_image_rgb)\n",
    "plt.title('Reconstructed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "table = plt.table(cellText=transposed_table_data,\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  bbox=[0, -0.55, 1, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best PSNR Selection with Template Matching\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import sys\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# -----------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------------\n",
    "# Load Model\n",
    "# -----------------------------------\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(experiment_ids=experiment.experiment_id, order_by=[\"attributes.start_time DESC\"])\n",
    "run_id = runs[0].info.run_id  # Get the last run\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment {experiment.name}\")\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    \"\"\"Calculate PSNR between two [0,1] tensor images using PyTorch functions.\"\"\"\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Function to align and update bboxes using template matching per digit\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        # Extract original digit\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window in reconstructed image\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Extract aligned digit\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Compute metrics\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "# -----------------------------------\n",
    "# Compute PSNR Heatmap\n",
    "# -----------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_avg = {}\n",
    "psnr_dict_worst = {}\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta, noise_level = metadata['alpha'], metadata['beta'], metadata['noise_level']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "\n",
    "    index = metadata['index']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    # Load images as tensors\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_img = model(distorted_img)\n",
    "        reconstructed_img = torch.clamp(reconstructed_img, 0, 1)\n",
    "\n",
    "    # Convert images to NumPy\n",
    "    original_np = original_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Apply template matching alignment per digit\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "    avg_psnr = np.mean(psnr_per_number) if psnr_per_number else 0\n",
    "    worst_psnr = min(psnr_per_number, default=0)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_avg:\n",
    "        psnr_dict_avg[(alpha, beta)] = []\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "    psnr_dict_avg[(alpha, beta)].append(avg_psnr)\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "\n",
    "# Average over multiple images if any\n",
    "for key in psnr_dict_avg:\n",
    "    psnr_dict_avg[key] = np.mean(psnr_dict_avg[key])\n",
    "    psnr_dict_worst[key] = np.mean(psnr_dict_worst[key])\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_avg.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_avg.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "psnr_matrix_avg = np.full((num_betas, num_alphas), np.nan)\n",
    "alpha_to_index = {val: i for i, val in enumerate(alpha_values)}\n",
    "beta_to_index = {val: i for i, val in enumerate(beta_values)}\n",
    "\n",
    "# Populate the PSNR matrix\n",
    "for (a, b), val in psnr_dict_avg.items():\n",
    "    psnr_matrix_avg[beta_to_index[b], alpha_to_index[a]] = val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image details for a given alpha,beta function\n",
    "\n",
    "# -----------------------------------\n",
    "# Function to show image details for a given alpha,beta\n",
    "# Using the same template matching approach inside show_image_details_for\n",
    "# -----------------------------------\n",
    "def show_image_details_for(alpha, beta, data_dir, model, device):\n",
    "    metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata.get('alpha') == alpha and metadata.get('beta') == beta:\n",
    "            found_file = {\n",
    "                \"metadata_file\": meta_file,\n",
    "                \"index\": metadata.get('index'),\n",
    "                \"digit_bboxes\": metadata.get('digit_bboxes'),\n",
    "                \"plate_number\": metadata.get('plate_number')\n",
    "            }\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(f\"No images found for alpha={alpha}, beta={beta}.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "\n",
    "    index = found_file['index']\n",
    "    original_image_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_image_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    original_img = to_tensor(Image.open(original_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_tensor = model(distorted_img)\n",
    "        reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    # Align and update bboxes with template matching\n",
    "    def calc_psnr_ssim(original_image, reconstructed_image, digit_bboxes):\n",
    "        # We'll reuse align_and_update_bboxes here to get aligned results\n",
    "        psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "        return psnr_vals, ssim_vals, updated_bboxes\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = calc_psnr_ssim(original_img, reconstructed_tensor, found_file['digit_bboxes'])\n",
    "\n",
    "    reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "    reconstructed_show = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "    original_image_cv = cv2.imread(original_image_path)\n",
    "\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "        cv2.putText(original_image_cv, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "    for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(reconstructed_show, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "        cv2.putText(reconstructed_show, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "    reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "    for i, (p, s) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14, 7))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(reconstructed_image_rgb)\n",
    "    plt.title('Reconstructed Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0, -0.55, 1, 0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------\n",
    "# Display Heatmap and Add Click Event\n",
    "# -----------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(psnr_matrix_avg, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "plt.title(\"Average PSNR per Digit\")\n",
    "plt.colorbar(label='PSNR (dB)')\n",
    "plt.xticks(range(0, num_alphas, 5), alpha_values[::5])\n",
    "plt.yticks(range(0, num_betas, 5), beta_values[::5])\n",
    "plt.xlabel(\"Alpha (degrees)\")\n",
    "plt.ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        psnr_value = psnr_matrix_avg[row, col]\n",
    "        return f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: {psnr_value:.2f} dB\" if not np.isnan(psnr_value) else f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: N/A\"\n",
    "    return \"Alpha: N/A, Beta: N/A\"\n",
    "\n",
    "plt.gca().format_coord = format_coord\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == plt.gca():\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta, data_dir, model, device)\n",
    "\n",
    "plt.gcf().canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Image Analysis with Metadata Retrieval and Visualization\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load (if needed; assuming similar to Code 1)\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap Visualization of average PSNR, SSIM, and OCR Metrics with Interactive Analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data_test\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(reconstructed_bgr, updated_bboxes, plate_number_gt):\n",
    "    recognized_digits = []\n",
    "    M = 16\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - M)\n",
    "        y1 = max(0, y - M)\n",
    "        x2 = min(reconstructed_bgr.shape[1], x + w + M)\n",
    "        y2 = min(reconstructed_bgr.shape[0], y + h + M)\n",
    "        digit_patch = reconstructed_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# -----------------------------------\n",
    "# Compute metrics for each (alpha,beta)\n",
    "# -----------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_avg = {}\n",
    "ssim_dict_avg = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    index = metadata['index']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_img = model(distorted_img)\n",
    "        reconstructed_img = torch.clamp(reconstructed_img, 0, 1)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "    avg_psnr = np.mean(psnr_per_number) if psnr_per_number else 0.0\n",
    "    avg_ssim = np.mean(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    image_bgr = (reconstructed_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_avg:\n",
    "        psnr_dict_avg[(alpha, beta)] = []\n",
    "        ssim_dict_avg[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_avg[(alpha, beta)].append(avg_psnr)\n",
    "    ssim_dict_avg[(alpha, beta)].append(avg_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "# Average if multiple images per angle (if any)\n",
    "for key in psnr_dict_avg:\n",
    "    psnr_dict_avg[key] = np.mean(psnr_dict_avg[key])\n",
    "    ssim_dict_avg[key] = np.mean(ssim_dict_avg[key])\n",
    "    ocr_acc_dict_avg[key] = np.mean(ocr_acc_dict_avg[key])\n",
    "    ocr_bin_dict_avg[key] = np.mean(ocr_bin_dict_avg[key])\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_avg.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_avg.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_index = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_index = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val in data_dict.items():\n",
    "        mat[beta_to_index[b], alpha_to_index[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix_avg = create_matrix_from_dict(psnr_dict_avg)\n",
    "ssim_matrix_avg = create_matrix_from_dict(ssim_dict_avg)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)\n",
    "\n",
    "# -----------------------------------\n",
    "# Interactive Plot with Buttons\n",
    "# -----------------------------------\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.subplots_adjust(bottom=0.2)  # space for buttons\n",
    "\n",
    "im = ax.imshow(psnr_matrix_avg, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Average PSNR per Digit\")\n",
    "cb = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        if current_metric == 'PSNR':\n",
    "            val = psnr_matrix_avg[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, PSNR: {val:.2f} dB\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'SSIM':\n",
    "            val = ssim_matrix_avg[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, SSIM: {val:.3f}\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Accuracy':\n",
    "            val = ocr_acc_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Acc: {val*100:.2f}%\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Binary':\n",
    "            val = ocr_bin_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Binary: {val:.0f}\" if not np.isnan(val) else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    # Find the file again\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    index = found_file['index']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructed_tensor = model(distorted_img)\n",
    "        reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, found_file['digit_bboxes'])\n",
    "\n",
    "    reconstructed_bgr = (reconstructed_np*255).astype(np.uint8)\n",
    "    reconstructed_bgr = cv2.cvtColor(reconstructed_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(reconstructed_bgr, updated_bboxes, plate_number_gt)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    reconstructed_show = reconstructed_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(reconstructed_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(reconstructed_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(reconstructed_image_rgb)\n",
    "    plt.title(f'Reconstructed Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Add buttons to switch between metrics\n",
    "ax_psnr = plt.axes([0.1, 0.05, 0.1, 0.05])\n",
    "ax_ssim = plt.axes([0.22, 0.05, 0.1, 0.05])\n",
    "ax_ocr_acc = plt.axes([0.34, 0.05, 0.12, 0.05])\n",
    "ax_ocr_bin = plt.axes([0.48, 0.05, 0.1, 0.05])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix_avg\n",
    "        title = \"Average PSNR per Digit\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix_avg\n",
    "        title = \"Average SSIM per Digit\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0,num_alphas,5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0,num_betas,5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "    ax.format_coord = format_coord\n",
    "    fig.colorbar(im, ax=ax, label=cbar_label)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "current_metric = 'PSNR'  # default\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap Visualization of worst PSNR, worst SSIM, and OCR Metrics with Interactive Analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# --------------------\n",
    "# Functions \n",
    "# --------------------\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "def align_and_update_bboxes(original_np, generated_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(generated_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(generated_np.shape[0], y + h + search_margin)\n",
    "        search_region = generated_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        aligned_digit = generated_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin):\n",
    "    recognized_digits = []\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - margin)\n",
    "        y1 = max(0, y - margin)\n",
    "        x2 = min(image_bgr.shape[1], x + w + margin)\n",
    "        y2 = min(image_bgr.shape[0], y + h + margin)\n",
    "        \n",
    "        digit_patch = image_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# --------------------------------------\n",
    "# Compute metrics for each (alpha, beta)\n",
    "# --------------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_worst = {}\n",
    "ssim_dict_worst = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    index = metadata['index']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_img = model(distorted_img)\n",
    "        generated_img = torch.clamp(generated_img, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, generated_np, digit_bboxes)\n",
    "\n",
    "    # Take the worst (minimum) PSNR and SSIM values across all digits for this image\n",
    "    worst_psnr = np.min(psnr_per_number) if psnr_per_number else 0.0\n",
    "    worst_ssim = np.min(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    image_bgr = (generated_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_worst:\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "        ssim_dict_worst[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "    ssim_dict_worst[(alpha, beta)].append(worst_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_worst.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_worst.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_index = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_index = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val_list  in data_dict.items():\n",
    "        val = np.min(val_list) if val_list else np.nan\n",
    "        mat[beta_to_index[b], alpha_to_index[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix = create_matrix_from_dict(psnr_dict_worst)\n",
    "ssim_matrix = create_matrix_from_dict(ssim_dict_worst)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plot with Buttons\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.subplots_adjust(bottom=0.2)  # space for buttons\n",
    "\n",
    "im = ax.imshow(psnr_matrix, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Worst PSNR per Image (Minimum Digit PSNR)\")\n",
    "cb = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        if current_metric == 'PSNR':\n",
    "            val = psnr_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, Worst PSNR: {val:.2f} dB\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'SSIM':\n",
    "            val = ssim_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, Worst SSIM: {val:.3f}\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Accuracy':\n",
    "            val = ocr_acc_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Acc: {val*100:.2f}%\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Binary':\n",
    "            val = ocr_bin_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Binary: {val:.0f}\" if not np.isnan(val) else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    index = found_file['index']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tensor = model(distorted_img)\n",
    "        generated_tensor = torch.clamp(generated_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, generated_np, found_file['digit_bboxes'])\n",
    "\n",
    "    generated_bgr = (generated_np*255).astype(np.uint8)\n",
    "    generated_bgr = cv2.cvtColor(generated_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(generated_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    generated_show = generated_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(generated_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(generated_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    generated_image_rgb = cv2.cvtColor(generated_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(generated_image_rgb)\n",
    "    plt.title(f'Generated Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Add buttons to switch between metrics\n",
    "ax_psnr = plt.axes([0.1, 0.05, 0.1, 0.05])\n",
    "ax_ssim = plt.axes([0.22, 0.05, 0.1, 0.05])\n",
    "ax_ocr_acc = plt.axes([0.34, 0.05, 0.12, 0.05])\n",
    "ax_ocr_bin = plt.axes([0.48, 0.05, 0.1, 0.05])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix\n",
    "        title = \"Worst PSNR per Image (Minimum Digit PSNR)\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix\n",
    "        title = \"Worst SSIM per Image (Minimum Digit SSIM)\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0,num_alphas,5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0,num_betas,5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "    ax.format_coord = format_coord\n",
    "    fig.colorbar(im, ax=ax, label=cbar_label)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "current_metric = 'PSNR'  # default\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from run 2fe6632315c74e428874491ae276a6d2 in experiment 'Unet' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|| 8100/8100 [42:44<00:00,  3.16plate/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
