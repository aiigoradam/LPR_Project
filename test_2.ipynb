{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap Visualization of average PSNR, SSIM, and OCR Metrics with Interactive Analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data_test\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(reconstructed_bgr, updated_bboxes, plate_number_gt):\n",
    "    recognized_digits = []\n",
    "    M = 16\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - M)\n",
    "        y1 = max(0, y - M)\n",
    "        x2 = min(reconstructed_bgr.shape[1], x + w + M)\n",
    "        y2 = min(reconstructed_bgr.shape[0], y + h + M)\n",
    "        digit_patch = reconstructed_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# -----------------------------------\n",
    "# Compute metrics for each (alpha,beta)\n",
    "# -----------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_avg = {}\n",
    "ssim_dict_avg = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    index = metadata['index']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_img = model(distorted_img)\n",
    "        reconstructed_img = torch.clamp(reconstructed_img, 0, 1)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "    avg_psnr = np.mean(psnr_per_number) if psnr_per_number else 0.0\n",
    "    avg_ssim = np.mean(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    image_bgr = (reconstructed_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_avg:\n",
    "        psnr_dict_avg[(alpha, beta)] = []\n",
    "        ssim_dict_avg[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_avg[(alpha, beta)].append(avg_psnr)\n",
    "    ssim_dict_avg[(alpha, beta)].append(avg_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "# Average if multiple images per angle (if any)\n",
    "for key in psnr_dict_avg:\n",
    "    psnr_dict_avg[key] = np.mean(psnr_dict_avg[key])\n",
    "    ssim_dict_avg[key] = np.mean(ssim_dict_avg[key])\n",
    "    ocr_acc_dict_avg[key] = np.mean(ocr_acc_dict_avg[key])\n",
    "    ocr_bin_dict_avg[key] = np.mean(ocr_bin_dict_avg[key])\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_avg.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_avg.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_index = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_index = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val in data_dict.items():\n",
    "        mat[beta_to_index[b], alpha_to_index[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix_avg = create_matrix_from_dict(psnr_dict_avg)\n",
    "ssim_matrix_avg = create_matrix_from_dict(ssim_dict_avg)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)\n",
    "\n",
    "# -----------------------------------\n",
    "# Interactive Plot with Buttons\n",
    "# -----------------------------------\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.subplots_adjust(bottom=0.2)  # space for buttons\n",
    "\n",
    "im = ax.imshow(psnr_matrix_avg, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Average PSNR per Digit\")\n",
    "cb = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        if current_metric == 'PSNR':\n",
    "            val = psnr_matrix_avg[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, PSNR: {val:.2f} dB\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'SSIM':\n",
    "            val = ssim_matrix_avg[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, SSIM: {val:.3f}\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Accuracy':\n",
    "            val = ocr_acc_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Acc: {val*100:.2f}%\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Binary':\n",
    "            val = ocr_bin_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Binary: {val:.0f}\" if not np.isnan(val) else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    # Find the file again\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    index = found_file['index']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructed_tensor = model(distorted_img)\n",
    "        reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, found_file['digit_bboxes'])\n",
    "\n",
    "    reconstructed_bgr = (reconstructed_np*255).astype(np.uint8)\n",
    "    reconstructed_bgr = cv2.cvtColor(reconstructed_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(reconstructed_bgr, updated_bboxes, plate_number_gt)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    reconstructed_show = reconstructed_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(reconstructed_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(reconstructed_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(reconstructed_image_rgb)\n",
    "    plt.title(f'Reconstructed Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Add buttons to switch between metrics\n",
    "ax_psnr = plt.axes([0.1, 0.05, 0.1, 0.05])\n",
    "ax_ssim = plt.axes([0.22, 0.05, 0.1, 0.05])\n",
    "ax_ocr_acc = plt.axes([0.34, 0.05, 0.12, 0.05])\n",
    "ax_ocr_bin = plt.axes([0.48, 0.05, 0.1, 0.05])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix_avg\n",
    "        title = \"Average PSNR per Digit\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix_avg\n",
    "        title = \"Average SSIM per Digit\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0,num_alphas,5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0,num_betas,5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "    ax.format_coord = format_coord\n",
    "    fig.colorbar(im, ax=ax, label=cbar_label)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "current_metric = 'PSNR'  # default\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap Visualization of worst PSNR, worst SSIM, and OCR Metrics with Interactive Analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# --------------------\n",
    "# Functions \n",
    "# --------------------\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "def align_and_update_bboxes(original_np, generated_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(generated_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(generated_np.shape[0], y + h + search_margin)\n",
    "        search_region = generated_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        aligned_digit = generated_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin):\n",
    "    recognized_digits = []\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - margin)\n",
    "        y1 = max(0, y - margin)\n",
    "        x2 = min(image_bgr.shape[1], x + w + margin)\n",
    "        y2 = min(image_bgr.shape[0], y + h + margin)\n",
    "        \n",
    "        digit_patch = image_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# --------------------------------------\n",
    "# Compute metrics for each (alpha, beta)\n",
    "# --------------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_worst = {}\n",
    "ssim_dict_worst = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    index = metadata['index']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_img = model(distorted_img)\n",
    "        generated_img = torch.clamp(generated_img, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, generated_np, digit_bboxes)\n",
    "\n",
    "    # Take the worst (minimum) PSNR and SSIM values across all digits for this image\n",
    "    worst_psnr = np.min(psnr_per_number) if psnr_per_number else 0.0\n",
    "    worst_ssim = np.min(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    image_bgr = (generated_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_worst:\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "        ssim_dict_worst[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "    ssim_dict_worst[(alpha, beta)].append(worst_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_worst.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_worst.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_index = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_index = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val_list  in data_dict.items():\n",
    "        val = np.min(val_list) if val_list else np.nan\n",
    "        mat[beta_to_index[b], alpha_to_index[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix = create_matrix_from_dict(psnr_dict_worst)\n",
    "ssim_matrix = create_matrix_from_dict(ssim_dict_worst)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plot with Buttons\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.subplots_adjust(bottom=0.2)  # space for buttons\n",
    "\n",
    "im = ax.imshow(psnr_matrix, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Worst PSNR per Image (Minimum Digit PSNR)\")\n",
    "cb = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        if current_metric == 'PSNR':\n",
    "            val = psnr_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, Worst PSNR: {val:.2f} dB\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'SSIM':\n",
    "            val = ssim_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, Worst SSIM: {val:.3f}\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Accuracy':\n",
    "            val = ocr_acc_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Acc: {val*100:.2f}%\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Binary':\n",
    "            val = ocr_bin_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Binary: {val:.0f}\" if not np.isnan(val) else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    index = found_file['index']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{index}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{index}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tensor = model(distorted_img)\n",
    "        generated_tensor = torch.clamp(generated_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, generated_np, found_file['digit_bboxes'])\n",
    "\n",
    "    generated_bgr = (generated_np*255).astype(np.uint8)\n",
    "    generated_bgr = cv2.cvtColor(generated_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(generated_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    generated_show = generated_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(generated_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(generated_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    generated_image_rgb = cv2.cvtColor(generated_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(generated_image_rgb)\n",
    "    plt.title(f'Generated Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Add buttons to switch between metrics\n",
    "ax_psnr = plt.axes([0.1, 0.05, 0.1, 0.05])\n",
    "ax_ssim = plt.axes([0.22, 0.05, 0.1, 0.05])\n",
    "ax_ocr_acc = plt.axes([0.34, 0.05, 0.12, 0.05])\n",
    "ax_ocr_bin = plt.axes([0.48, 0.05, 0.1, 0.05])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix\n",
    "        title = \"Worst PSNR per Image (Minimum Digit PSNR)\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix\n",
    "        title = \"Worst SSIM per Image (Minimum Digit SSIM)\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0,num_alphas,5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0,num_betas,5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "    ax.format_coord = format_coord\n",
    "    fig.colorbar(im, ax=ax, label=cbar_label)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "current_metric = 'PSNR'  # default\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
